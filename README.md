# LogisticRegression
#### Hi there! This is just a quick little activity I did in my spare time on Logistic Regression. This is a skillset that I had zero knowledge on a year ago, so I am very proud of how far I've come! 

##### The purpose of this project was to predict healthy (0) and high risk (1) loans. Identifying healthy and high-risk loans is imperative for financial institutions to effectively manage risk and make informed lending decisions. Unfortunately, credit risk poses a classification problem that’s inherently imbalanced, and this is because healthy loans easily outnumber risky loans. In this project, I used various techniques to train and evaluate models with imbalanced classes. I used a dataset of historical lending activity from a peer-to-peer lending services company to build a model that was able to identify the creditworthiness of borrowers. I split my data into training and testing sets to evaluate the model's performance. I then defined and fit my logistic regression model to the training data. After making my initial prediction on the testing set, I calculated the performance metrics to assess the model’s effectiveness. Finally, I resampled my training data (using RandomOverSampler) to address class imbalance and improve prediction accuracy. 

##### My results were as follows: 
##### 1. Logistic Regression Model 1: This model predicts healthy loans (0) with 100% accuracy. It predicts high-risk loans (1) with 88% accuracy. For healthy (0) loans, the precision score was 100% and the recall score was 99%. For high risk (1) loans, the precision score was 85% and the recall score was 91%.

##### 2. Logistic Regression Model 2: This model predicts healthy loans (0) with 100% accuracy. It predicts high-risk loans (1) with 91% accuracy. For healthy (0) loans, the precision score was 100% and the recall score was 99%. For high risk (1) loans, the precision score was 84% and the recall score was 99%.


##### Based on the data I used, the Logistic Regression model seemed to predict our initial data very well. Once I oversampled my training data, the model performed even better. The pros of resampling my training data are 1.) improve model performances, 2.) mitigate bias in logistic regression models caused by imbalanced class distributions, 3.) preserve valuable information from the original dataset while addressing a class imbalance. The cons of resampling my training data are 1.) risk of overfitting, and 2.) potential loss of information. The decision to oversample the data helped to prevent any potential loss of information, so I did not see any issues there. Overall, I highly recommend using these models given that they performed very efficiently despite the potential cons. 

